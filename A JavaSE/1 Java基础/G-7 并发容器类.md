[TOC]

### 并发容器类

#### 1 CopyOnWriteArrayList

##### ① 概述

- 实现了 **List** 接口，与其他 List 实现类用法类似。
- 是线程安全的，可以被多个线程并发访问。
- 它的迭代器不支持修改操作，但也不会抛出 ConcurrentModificationException。迭代时不需要像同步容器那边对整个列表对象加锁。
- 它以原子方式支持一些复合操作。

##### ② 适用场景

CopyOnWriteArrayList 在**写操作**的**同时**允许读操作，大大提高了读操作的性能，因此很适合**读多写少**的应用场景，不适合数组很大且需要频繁修改的场景，它是以**优化读**为目标的。

但是 CopyOnWriteArrayList 有其**缺陷**：

- 内存占用：在**写操作**时需要复制一个**新的数组**，使得内存占用为原来的**两倍**左右；
- 数据不一致：读操作**不能读取实时性**的数据，因为部分写操作的数据还**未同步**到读数组中。

所以 CopyOnWriteArrayList **不适合内存敏感以及对实时性要求很高**的场景。

基本使用与 List 类似。

```java
public static void main(String[] args) {
    List<Integer> list = new CopyOnWriteArrayList<Integer>();
    list.add(1);
    list.add(2);
}
```



##### ③ 成员属性

重要的成员属性。

```java
/** The lock protecting all mutators */
final transient ReentrantLock lock = new ReentrantLock();

// 存放元素 volatile保证内存可见性
private transient volatile Object[] array;
```

可以看到，CopyOnWriteArrayList 使用了 **ReentrantLock** 来支持并发操作，array 就是实际**存放数据的数组**对象。ReentrantLock 是一种支持重入的独占锁，任意时刻只允许一个线程获得锁，所以可以安全的并发去写数组



##### ④ 读写分离

**写操作**在一个==**复制的数组**==上进行，**读操作**还是在**原始数组**中进行，**读写分离**，互不影响。

**写**操作需要加**锁**，防止并发写入时导致写入数据丢失。

写操作结束之后需要把原始数组**指向**新的复制数组。**读不需要锁，可以并行**，**读写也可以并行**，但多个线程不能同时写，每个写操作都需要先获取锁。

```java
public boolean add(E e) {
    final ReentrantLock lock = this.lock;	// 加锁
    lock.lock();
    try {
        Object[] elements = getArray();
        int len = elements.length;
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        newElements[len] = e;
        // 指向复制完成的新数组
        setArray(newElements);
        return true;
    } finally {
        lock.unlock();		// 释放锁
    }
}

// 修改内部数组引用
final void setArray(Object[] a) {
    array = a;
}
```

```java
@SuppressWarnings("unchecked")	
private E get(Object[] a, int index) {	// 直接读 可以并行
    return (E) a[index];
}
```

**每次修改操作，都会创建一个数组**，复制原数组的内容到新数组，在新数组上进行修改，然后以原子方式设置内部的数组引用，这就是**写时复制**。换句话说，数组内容是**只读**的，**写操作都是通过新建数组**，然后**原子性**的修改数组引用来实现的。

CopyOnWriteArrayList 的缺点就是**修改代价十分昂贵**，**每次修改都伴随着一次的数组复制**；但同时优点也十分明显，就是在并发下不会产生任何的线程安全问题，也就是**绝对的线程安全**。



##### ⑤ 小结

CopyOnWriteArrayList 这个并发组件，其实反映的是两个十分重要的**分布式**理念：

**（1）读写分离**

我们读取 CopyOnWriteArrayList 的时候读取的是 CopyOnWriteArrayList 中的 Object[] array，但是修改的时候，操作的是一个**新的** Object[] array，读和写操作的不是同一个对象，这就是读写分离。这种技术数据库用的非常多，在高并发下为了缓解数据库的压力，即使做了缓存也要对数据库做读写分离，读的时候使用读库，写的时候使用写库，然后读库、写库之间进行一定的同步，这样就避免同一个库上读、写的 IO 操作太多

**（2）最终一致**

对 CopyOnWriteArrayList 来说，线程 1 读取集合里面的数据，未必是最新的数据。因为线程 2、线程 3、线程 4 四个线程都修改了 CopyOnWriteArrayList 里面的数据，但是线程 1 拿到的还是最老的那个 Object[] array，新添加进去的数据并没有，所以线程 1 读取的内容**未必准确**。不过这些数据虽然对于线程 1 是不一致的，但是对于之后的线程一定是一致的，它们拿到的 Object[] array 一定是三个线程都操作完毕之后的 Object array[]，这就是**最终一致**。最终一致对于分布式系统也非常重要，它通过容忍一定时间的数据不一致，提升整个分布式系统的可用性与分区容错性。当然，最终一致并不是任何场景都适用的，像火车站售票这种系统用户对于数据的实时性要求非常非常高，就必须做成强一致性的。

最后总结一点，随着 CopyOnWriteArrayList 中元素的增加，CopyOnWriteArrayList 的修改代价将越来越昂贵，因此，**CopyOnWriteArrayList适用于==读操作远多于修改操作==的并发场景中**。



##### ⑥ CopyOnWriteArraySet

- 实现了 **Set** 接口，不包含重复元素。
- 内部通过 CopyOnWriteArrayList 实现，性能较低，**不适用于元素个数很多**的结合。如果元素较多可以考虑 ConcurrentHashMap 或 ConcurrentSkipListSet 这两个类。





#### ==2 ConcurrentHashMap==

##### ① 概述

**特点**

- 并发安全，支持高并发，**读操作完全并行**，**写操作==一定程度==并行**。
- 直接支持一些原子复合操作
- 与同步容器相比，迭代不需要加锁
- 弱一致性

**为何使用**

并发更新情况下，HashMap 可能出现**死循环**，多出现在多个线程**同时扩容哈希表**的时候，占满 CPU。Collections.synchronizedMap 可以生成一个同步容器可以避免死循环，但是同步容器有几个问题：

1、每个方法都需要同步，并发度较低。

2、对于迭代和复合操作，需要调用方加锁。

ConcurrentHashMap 则没有上述的问题。同样实现了 Map 接口，也是基于**哈希表**实现。



##### ② 存储结构

```java
static final class HashEntry<K,V> {
    final int hash;
    final K key;
    volatile V value;
    volatile HashEntry<K,V> next;
}
```

ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了==**分段锁（Segment）**==，每个分段锁维护着**几个桶**（HashEntry），多个线程可以同时访问==**不同分段锁**==上的桶，从而使其并发度更高（最大并发度就是 **Segment 的个数**，Segment 个数的线程可以同时访问）。将数据分为**多个段**，**每个段有一个独立的锁，每个段相当于一个独立的哈希表**。

采用分段技术，可以大大提高并发度，多个段之间可以**并行读写**。默认段是 16 个。实现的效果是对于读操作可以并行，对于**写操作需要获取锁**，不能并行。

Segment 继承自 **ReentrantLock**。具有显式锁的一些机制。

```java
static final class Segment<K,V> extends ReentrantLock implements Serializable {

    private static final long serialVersionUID = 2249069246763182397L;

    static final int MAX_SCAN_RETRIES =
        Runtime.getRuntime().availableProcessors() > 1 ? 64 : 1;

    transient volatile HashEntry<K,V>[] table;
	// 该segment中键值对数量
    transient int count;

    transient int modCount;

    transient int threshold;

    final float loadFactor;
}
```

```java
// 多个段
final Segment<K,V>[] segments;
```

默认的**并发级别**为 16，也就是说默认创建 **16 个** Segment。

```java
static final int DEFAULT_CONCURRENCY_LEVEL = 16; 
```

![1563604891272](assets/1563604891272.png)



##### ③ size 操作

每个 Segment 维护了一个 **count** 变量来统计该 Segment 中的**键值对个数**。

```java
/**
 * The number of elements. Accessed only either within locks
 * or among other volatile reads that maintain visibility.
 */
transient int count;
```

在执行 size 操作时，需要遍历**所有** Segment 然后把 count **累计**起来。

ConcurrentHashMap 在执行 size 操作时**先尝试不加锁**，如果**连续两次不加锁**操作得到的**结果一致**，那么可以认为这个结果是正确的。

**尝试次数**使用 **RETRIES_BEFORE_LOCK** 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。

如果尝试的次数**超过 3 次**，就需要对**每个 Segment 加锁**。

```java
/**
 * Number of unsynchronized retries in size and containsValue
 * methods before resorting to locking. This is used to avoid
 * unbounded retries if tables undergo continuous modification
 * which would make it impossible to obtain an accurate result.
 */
static final int RETRIES_BEFORE_LOCK = 2;

public int size() {
    // Try a few times to get accurate count. On failure due to
    // continuous async changes in table, resort to locking.
    final Segment<K,V>[] segments = this.segments;
    int size;
    boolean overflow; // true if size overflows 32 bits
    long sum;         // sum of modCounts
    long last = 0L;   // previous sum
    int retries = -1; // first iteration isn't retry
    try {
        for (;;) {
            // 超过尝试次数，则对每个 Segment 加锁
            if (retries++ == RETRIES_BEFORE_LOCK) {
                for (int j = 0; j < segments.length; ++j)
                    ensureSegment(j).lock(); // force creation
            }
            sum = 0L;
            size = 0;
            overflow = false;
            for (int j = 0; j < segments.length; ++j) {
                Segment<K,V> seg = segmentAt(segments, j);
                if (seg != null) {
                    sum += seg.modCount;
                    int c = seg.count;
                    if (c < 0 || (size += c) < 0)
                        overflow = true;
                }
            }
            // 连续两次得到的结果一致，则认为这个结果是正确的
            if (sum == last)
                break;
            last = sum;
        }
    } finally {
        if (retries > RETRIES_BEFORE_LOCK) {
            for (int j = 0; j < segments.length; ++j)
                segmentAt(segments, j).unlock();
        }
    }
    return overflow ? Integer.MAX_VALUE : size;
}
```



##### ④ JDK 1.8 的改动

JDK 1.7 使用**分段锁机制**来实现并发更新操作，核心类为 **Segment**，它继承自重入锁 ReentrantLock，并发度与 Segment 数量相等。

JDK 1.8 使用了 **==CAS 操作==**来支持**更高的并发度**，在 CAS 操作失败时使用**内置锁 synchronized**。不再使用分段锁！

并且 JDK 1.8 的实现也在链表过长时会转换为**红黑树**。



##### ⑤ 弱一致性

ConcurrentHaspMap 迭代器创建之后，就会按照哈希表结构遍历**读取每个元素**，但在遍历过程中，内部元素可能会因为其他线程的**写入修改发生变化**，如果变化发生在**已遍历的部分**，迭代器就不会反映出来，而如果变化部分发生在未遍历过的部分，迭代器就会发现并反映出来，这就是**弱一致性**。







#### 3 ConcurrentSkipListMap

##### ① 概述

ConcurrentSkipListMap 是基于 **SkipList** 实现的，SkipList 称为**跳表**。



**特点**

- 没有使用锁，所有操作都是**无阻塞**的，所有操作都**可以并行**，包括写，**多线程可以同时写**。
- 与 ConcurrentHashMap 类似，迭代器**不会抛出** ConcurrentModificationException，是**弱一致性**的，迭代可能反映最新修改也可能不反映。
- 实现了 ConcurrentMap 接口，支持一些原子复合操作。
- 与 TreeMap 一样可以**排序**，默认安装键的自然排序，也可以按照自定义比较器进行排序。



##### ② 原理分析

跳表是基于**链表**的，在链表的基础上增加了**多层索引**结构。

![1582800147086](assets/G-7%20%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E7%B1%BB/1582800147086.png)

最下面一层是最基本的**单向链表**，这是一个**有序**的链表。但是普通链表不能进行直接定位，所以不能进行二分查找。所以为了**快速查找**，使用了**多层索引**，**高层的索引节点一定同时是底层的索引节点**。每个索引节点有两个指针，一个向右指向统同层的索引节点，另一个向下指向下一层的索引节点或者基本链表节点。

基于上述结构就可以进行**二分查找**了。复杂度是O(logN)。







#### 参考资料

- https://www.cnblogs.com/xrq730/p/5020760.html